{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88abae87-f56b-401f-9be6-29ac75b6e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PROCESSING\n",
    "\n",
    "#Importing modules\n",
    "import pandas as pd\n",
    "\n",
    "#Reading in raw TSV data\n",
    "#low_memory = False due to mixed data types in columns 9, 11, 12, 13, 15\n",
    "df = pd.read_csv(\"/home/leelab/data/TCGA/kipan/kipan_clin_meth_20221210.tsv.gz\", sep = \"\\t\", low_memory = False)\n",
    "\n",
    "#Organizing dataframe\n",
    "df1 = df.iloc[:,[0,1,2,5,8] + list(range(17, 183218))] #Choosing specific columns\n",
    "df2 = df1.rename(columns={\"Unnamed: 0\":\"sampleID\"}) #Renaming first column\n",
    "\n",
    "#Re-ordering the stage column to the front\n",
    "col = df2.pop(\"stage\")\n",
    "df2.insert(1, col.name, col)\n",
    "\n",
    "#Removing rows in which \"stage\" is NaN\n",
    "df2.dropna(subset = [\"stage\"], inplace = True)\n",
    "\n",
    "#Transversing the dataframe and using the sampleID as the index (column name)\n",
    "df_flipped = df2.set_index(\"sampleID\").T\n",
    "\n",
    "#Changing the stage value to \"normal\" for all normal sampleID's\n",
    "for column in df_flipped.columns:\n",
    "    if df_flipped.loc[\"rcc\", column] == \"normal\":\n",
    "        df_flipped.loc[\"stage\", column] = \"normal\"\n",
    "\n",
    "#Extracting columns with each \"stage\" value\n",
    "normal = df_flipped.columns[df_flipped.loc[\"stage\"] == \"normal\"]\n",
    "stage_i = df_flipped.columns[df_flipped.loc[\"stage\"] == \"stage i\"]\n",
    "stage_ii = df_flipped.columns[df_flipped.loc[\"stage\"] == \"stage ii\"]\n",
    "stage_iii = df_flipped.columns[df_flipped.loc[\"stage\"] == \"stage iii\"]\n",
    "stage_iv = df_flipped.columns[df_flipped.loc[\"stage\"] == \"stage iv\"]\n",
    "\n",
    "#Reordering the columns\n",
    "cols_ordered = list(normal) + list(stage_i) + list(stage_ii) + list(stage_iii) + list(stage_iv)\n",
    "df_flipped1 = df_flipped[cols_ordered]\n",
    "\n",
    "#Converting from a \"view\" df to a \"copy\" df in order to modify it properly\n",
    "df_flipped2 = df_flipped1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332cd9ce-b402-4dd7-aa9b-dbd575a74dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLUSTERING\n",
    "\n",
    "#Importing modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skfuzzy as fuzz\n",
    "\n",
    "#Reading in data\n",
    "df = pd.read_csv(\"/home/leelab/jbregman/rcc_fcm/processing/processed.csv\", index_col = 0, low_memory = False)\n",
    "\n",
    "#Separating the \"mean\" columns\n",
    "df1 = df.iloc[list(range(4,150068)),[839,840,841,842,843]]\n",
    "df1.columns = [\"normal (N = 205)\", \"stage i (N = 344)\", \"stage ii (N = 74)\", \"stage iii (N = 137)\", \"stage iv (N = 79)\"]\n",
    "\n",
    "#Altering the mean values for each stage by making them relative to the normal value\n",
    "df2 = pd.DataFrame()\n",
    "df2[\"normal (N = 205)\"] = df1[\"normal (N = 205)\"] - df1[\"normal (N = 205)\"]\n",
    "df2[\"stage i (N = 344)\"] = df1[\"stage i (N = 344)\"] - df1[\"normal (N = 205)\"]\n",
    "df2[\"stage ii (N = 74)\"] = df1[\"stage ii (N = 74)\"] - df1[\"normal (N = 205)\"]\n",
    "df2[\"stage iii (N = 137)\"] = df1[\"stage iii (N = 137)\"] - df1[\"normal (N = 205)\"]\n",
    "df2[\"stage iv (N = 79)\"] = df1[\"stage iv (N = 79)\"] - df1[\"normal (N = 205)\"]\n",
    "\n",
    "#Standardizing the data\n",
    "df3 = df2.copy()\n",
    "df3.iloc[:,0] = df3.iloc[:,0]/df1.std(axis=1)\n",
    "df3.iloc[:,1] = df3.iloc[:,1]/df1.std(axis=1)\n",
    "df3.iloc[:,2] = df3.iloc[:,2]/df1.std(axis=1)\n",
    "df3.iloc[:,3] = df3.iloc[:,3]/df1.std(axis=1)\n",
    "df3.iloc[:,4] = df3.iloc[:,4]/df1.std(axis=1)\n",
    "\n",
    "#APPLYING FCM CLUSTERING ALGORITHM\n",
    "m = 1.1 #fuzziness parameter\n",
    "c =  9 #number of clusters\n",
    "\n",
    "np.random.seed(19) #random seed\n",
    "cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(df3.T, c, m, error=0.005, maxiter=5000)\n",
    "\n",
    "#Creating dataframe of the cluster probabilities for each cgID\n",
    "df_fuzz = pd.DataFrame(u.T, index = df3.index)\n",
    "\n",
    "#Function to return the index (column name) of the highest value in each row\n",
    "def find_max(row):\n",
    "    max_column = row.idxmax()\n",
    "    return max_column\n",
    "\n",
    "#Applying that function to the entire dataframe\n",
    "df_fuzz['Membership'] = df_fuzz.apply(find_max, axis=1)\n",
    "\n",
    "#Concatenating the dataframes together\n",
    "df_merged = pd.concat([df3, df_fuzz], axis = 1)\n",
    "\n",
    "#Sorting the rows so that membership is in increasing order\n",
    "df_sorted = df_merged.sort_values(by='Membership', key=lambda x: x.map({v: i for i, v in enumerate(list(range(0,c)))}))\n",
    "\n",
    "df_sorted.to_csv(f\"/home/leelab/jbregman/rcc_fcm/clustering/STAGE/csv/NEW_c=s{c}.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6a4815-b06c-4372-8d8f-35d3e144aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRAPHING\n",
    "\n",
    "#Importing modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skfuzzy as fuzz\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "#Defining number of clusters\n",
    "num_clusters = 8\n",
    "\n",
    "#Reading in data\n",
    "df = pd.read_csv(f\"/home/leelab/jbregman/rcc_fcm/clustering/stage/csv/NEW_c=s{num_clusters}.csv\", index_col = 0, low_memory = False) #Reading in CSV file\n",
    "probs = df.iloc[:, list(range(5, 5+num_clusters))] #Extracting probabilities\n",
    "max = probs.max(axis=1) \n",
    "df[\"max probability\"] = max #Adding a max probability column\n",
    "df_sorted = df.iloc[:,[0,1,2,3,4,num_clusters + 5,num_clusters + 6]] #Removing columns with probability values\n",
    "df_sorted1 = df_sorted[df_sorted[\"max probability\"] >= 0.99] #Creating a probability cutoff\n",
    "\n",
    "#DF used for creating charts (replacing cgID index with numbers)\n",
    "df_charts = df_sorted1.reset_index(drop = True)\n",
    "\n",
    "#Function to print the necessary dataframes and chart titles for the matrix\n",
    "def create_dfs(num_clusters):\n",
    "\n",
    "    #Creating a list \"indexes\" to store the indexes for each cluster (e.g., the row IDs belonging to each cluster from the df)\n",
    "    my_list = df_charts[\"Membership\"].tolist()\n",
    "    my_list_2 = list(range(0, num_clusters))\n",
    "    indexes = []\n",
    "    for i in my_list_2:\n",
    "        indexes.append(my_list.index(i))\n",
    "\n",
    "    indexes.insert(num_clusters, len(df_charts))\n",
    "\n",
    "    #Creating a list \"length_list\" to store the length of each cluster (e.g., the number of rows belonging to each cluster)\n",
    "    indexes2 = []\n",
    "    for j in range(len(indexes) - 1):\n",
    "        sublist = [indexes[j], indexes[j + 1]]\n",
    "        indexes2.append(sublist)\n",
    "\n",
    "    length_list = []\n",
    "    for sublist1 in indexes2:\n",
    "        diff = sublist1[1] - sublist1[0]\n",
    "        length_list.append(diff)\n",
    "\n",
    "    #Using the indexes list & length list to print the code needed for the matrix\n",
    "    for i in list(range(num_clusters)):\n",
    "        print(f\"df_c{i} = df_charts.iloc[list(range({indexes[i]},{indexes[i+1]})),[0,1,2,3,4,6]]\")\n",
    "        print(f\"df_c{i} = df_c{i}.reset_index(drop = True)\")\n",
    "\n",
    "    for i in list(range(num_clusters)):\n",
    "        print(f\"'Cluster {i + 1}/{num_clusters} (m = {length_list[i]})',\")\n",
    "\n",
    "create_dfs(num_clusters)\n",
    "\n",
    "df_c0 = df_charts.iloc[list(range(0,7629)),[0,1,2,3,4,6]]\n",
    "df_c0 = df_c0.reset_index(drop = True)\n",
    "df_c1 = df_charts.iloc[list(range(7629,32862)),[0,1,2,3,4,6]]\n",
    "df_c1 = df_c1.reset_index(drop = True)\n",
    "df_c2 = df_charts.iloc[list(range(32862,64397)),[0,1,2,3,4,6]]\n",
    "df_c2 = df_c2.reset_index(drop = True)\n",
    "df_c3 = df_charts.iloc[list(range(64397,92641)),[0,1,2,3,4,6]]\n",
    "df_c3 = df_c3.reset_index(drop = True)\n",
    "df_c4 = df_charts.iloc[list(range(92641,99154)),[0,1,2,3,4,6]]\n",
    "df_c4 = df_c4.reset_index(drop = True)\n",
    "df_c5 = df_charts.iloc[list(range(99154,105996)),[0,1,2,3,4,6]]\n",
    "df_c5 = df_c5.reset_index(drop = True)\n",
    "df_c6 = df_charts.iloc[list(range(105996,110367)),[0,1,2,3,4,6]]\n",
    "df_c6 = df_c6.reset_index(drop = True)\n",
    "df_c7 = df_charts.iloc[list(range(110367,118935)),[0,1,2,3,4,6]]\n",
    "df_c7 = df_c7.reset_index(drop = True)\n",
    "\n",
    "#Creating a list of these dataframes\n",
    "data_frames = [df_c0, df_c1, df_c2, df_c3, df_c4, df_c5, df_c6, df_c7] #, df_c8, df_c9,\n",
    "               #df_c10, df_c11, df_c12, df_c13, df_c14, df_c15, df_c16, df_c17, df_c18, df_c19]\n",
    "               #df_c20, df_c21, df_c22, df_c23, df_c24, df_c25, df_c26, df_c27, df_c28, df_c29,\n",
    "               #df_c30, df_c31, df_c32, df_c33, df_c34, df_c35, df_c36, df_c37, df_c38, df_c39]\n",
    "\n",
    "#Customizing a title for each dataframe\n",
    "titles = [\n",
    "'Cluster 1/8 (m = 7629)',\n",
    "'Cluster 2/8 (m = 25233)',\n",
    "'Cluster 3/8 (m = 31535)',\n",
    "'Cluster 4/8 (m = 28244)',\n",
    "'Cluster 5/8 (m = 6513)',\n",
    "'Cluster 6/8 (m = 6842)',\n",
    "'Cluster 7/8 (m = 4371)',\n",
    "'Cluster 8/8 (m = 8568)'\n",
    "         ]\n",
    "         \n",
    "#Creating the matrix (rows,columns) & (width, height)\n",
    "fig, axes = plt.subplots(3, 3, figsize = (30,25))\n",
    "fig.suptitle(\"Stage Cluster (C=8) Line Charts (p >= 0.99)\", fontsize = 35) #Adding a title for the matrix\n",
    "\n",
    "#Looping through each \"spot\" in the matrix and each dataframe to create the figure\n",
    "for i, (df, ax, title) in enumerate(zip(data_frames, axes.flat, titles)):\n",
    "    cmap = plt.get_cmap('plasma')  #Adding a color map\n",
    "    normalize = Normalize(vmin = 0.99, vmax = 1) #Setting the range of the color map \n",
    "    colors = [cmap(normalize(value)) for value in df['max probability']] #Using the probability values for the color map\n",
    "\n",
    "    #Looping through the dataframe to add the values\n",
    "    for index, row in df.iterrows():\n",
    "        #Adding the first 5 values from each row and using the first 5 columns to create the line chart\n",
    "        ax.plot(df.columns[:5], row.values[:5], label = f'Row {str(index)}', color = colors[index], alpha = 0.25)\n",
    "\n",
    "    #Adding individual chart details\n",
    "    ax.set_xlabel('Stage', fontsize=20)\n",
    "    ax.set_ylabel('Mean Methylation', fontsize=20)\n",
    "    ax.set_title(title, fontsize=25)\n",
    "    ax.tick_params(axis = 'x', rotation=90, labelsize=15)\n",
    "    #ax.set_ylim(df.loc[:, df.columns != 'max probability'].values.min() - 0.3, df.loc[:, df.columns != 'max probability'].values.max() + 0.3)\n",
    "    ax.set_ylim(-3,3)\n",
    "    \n",
    "#Creates one color bar for entire matrix\n",
    "sm = ScalarMappable(cmap=cmap, norm=normalize)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, label = 'Cluster Probability', cax = fig.add_axes([0.95, 0.15, 0.02, 0.7]))\n",
    "\n",
    "plt.subplots_adjust(top = 0.9, wspace = 0.4, hspace = 0.7) \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
